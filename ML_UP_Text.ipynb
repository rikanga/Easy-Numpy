{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_UP_Text",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyAhZxclduXkgpIDZ7F8rc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rikanga/Easy-Numpy/blob/main/ML_UP_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Text\n",
        "\n",
        "## 6.1 Cleaning Text\n",
        "\n",
        "**Problem**\n",
        "\n",
        "You have some unstructured text data and want to complete some basic cleaning.\n",
        "\n",
        "**Solution**\n",
        "\n",
        "Most basic text cleaning operations should only replace Python’s core string opera‐\n",
        "tions, in particular strip , replace , and split :"
      ],
      "metadata": {
        "id": "KX7Hm1rXHXCF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qX3XfhLUHNfK"
      },
      "outputs": [],
      "source": [
        "# Create text\n",
        "text_data = [\n",
        "             \"   Interrobang. By Aishwarya Henriette   \",\n",
        "             \"Parking And Going. By Karl Gautier\",\n",
        "             \"   Today Is The night. By Jarek Prakash   \"\n",
        "             ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip whiitespace\n",
        "strip_whitespace = [strip.strip() for strip in text_data]"
      ],
      "metadata": {
        "id": "3xu-BR5VIm_x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View strip_whitespace\n",
        "strip_whitespace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sDS5THGI3e-",
        "outputId": "3b4c4a68-2b43-49c7-8dc7-89f065863cef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interrobang. By Aishwarya Henriette',\n",
              " 'Parking And Going. By Karl Gautier',\n",
              " 'Today Is The night. By Jarek Prakash']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop\n",
        "remove_stop = [string.replace('.', '') for string in strip_whitespace]"
      ],
      "metadata": {
        "id": "HXhpNPXZI8Ey"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View remove_stop\n",
        "remove_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hjlPoUYJvEF",
        "outputId": "d251ff92-4fc5-48f8-dc0a-f55f692c5374"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interrobang By Aishwarya Henriette',\n",
              " 'Parking And Going By Karl Gautier',\n",
              " 'Today Is The night By Jarek Prakash']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function\n",
        "def capitalizer(string: str):\n",
        "  return string.upper()"
      ],
      "metadata": {
        "id": "jzEZ0nmlJyKe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply function\n",
        "[capitalizer(string) for string in remove_stop]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2lp5fFkKH9l",
        "outputId": "b6a4fbdb-6310-4ef7-9104-2e5533196377"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['INTERROBANG BY AISHWARYA HENRIETTE',\n",
              " 'PARKING AND GOING BY KARL GAUTIER',\n",
              " 'TODAY IS THE NIGHT BY JAREK PRAKASH']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USING REGULAR EXPRESSION\n",
        "# Load libray\n",
        "import re\n",
        "\n",
        "# Define the function\n",
        "def replace_letters_with_X(string:str):\n",
        "  return re.sub(r'[a-zA-Z]','X', string)"
      ],
      "metadata": {
        "id": "nbzezICZKQ1Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply function with re pattern\n",
        "[replace_letters_with_X(string) for string in remove_stop]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP6tRKagLdJQ",
        "outputId": "1c9c6882-25a9-4c41-f656-6a39ffc0e7d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['XXXXXXXXXXX XX XXXXXXXXX XXXXXXXXX',\n",
              " 'XXXXXXX XXX XXXXX XX XXXX XXXXXXX',\n",
              " 'XXXXX XX XXX XXXXX XX XXXXX XXXXXXX']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Parsing and Cleaning HTML\n",
        "\n",
        "**Problem**\n",
        "\n",
        "You have text data with HTML elements and want to extract just the text.\n",
        "\n",
        "**Solution**\n",
        "\n",
        "Use Beautiful Soup’s extensive set of options to parse and extract from HTML:"
      ],
      "metadata": {
        "id": "-MHlXvQaQ-QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZjRXHGHQRkL",
        "outputId": "e80b15b1-171c-4a2c-9d05-54d0a889b61d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libray\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "noOxz4rfLotC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create some HTML code\n",
        "html = \"\"\"\n",
        "<div class='full_name'><span style='font-weight:bold'>\n",
        "Masego</span> Azra</div>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YAdY7wnuQMVO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parse html\n",
        "soup = BeautifulSoup(html, 'lxml')"
      ],
      "metadata": {
        "id": "GMY2R-Z9Rq5S"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQgM62EBR8IF",
        "outputId": "4a073a74-1cda-485e-c651-a10861bb10d4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<html><body><div class=\"full_name\"><span style=\"font-weight:bold\">\n",
              "Masego</span> Azra</div>\n",
              "</body></html>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the class with full_name, show text\n",
        "soup.find(\"div\", {'class':'full_name'}).text.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UQcfFsVISIwk",
        "outputId": "65fa3688-664f-423e-fc4d-078d1c0d381d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Masego Azra'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('span', {\"style\":'font-weight:bold'}).text.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZBxXdshUSeYa",
        "outputId": "95e2d2ac-c3a0-44b1-acb0-4971cf650c77"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Masego'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ue_eWaYyT3JE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Removing Punctuation\n",
        "\n",
        "**Problem**\n",
        "\n",
        "You have a feature of text data and want to remove punctuation.\n",
        "\n",
        "**Solution**\n",
        "\n",
        "Define a function that uses translate with a dictionary of punctuation characters:"
      ],
      "metadata": {
        "id": "tZs2-KR0WH56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import sys\n",
        "import unicodedata"
      ],
      "metadata": {
        "id": "itBzmKs9VTg_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text\n",
        "text_data = [\n",
        "             'Hi!!!! I. Love. This. Song....',\n",
        "             '10000% Agree!!!! #LoveIT',\n",
        "             'Right?!?!']"
      ],
      "metadata": {
        "id": "rolQTP82XUOZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_found = [re.findall(r'[a-zA-Z0-9]+', x) for x in text_data]\n",
        "word_found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl9fbFOMZmjY",
        "outputId": "eefb57a0-1871-4887-f182-7e99dbaa1dd9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Hi', 'I', 'Love', 'This', 'Song'], ['10000', 'Agree', 'LoveIT'], ['Right']]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = [','.join(x) for x in word_found]"
      ],
      "metadata": {
        "id": "gf_-7jsSaLAq"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[string.replace(',', ' ') for string in new_data]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YmhxBG4c3sg",
        "outputId": "72953eab-f7e0-41ec-db56-b8126de060d7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.4 Tokenizing Text\n",
        "\n",
        "**Problem**\n",
        "\n",
        "You have text and want to break it up into individual words.\n",
        "\n",
        "**Solution**\n",
        "\n",
        "Natural Language Toolkit for Python (NLTK) has a powerful set of text manipulation\n",
        "operations, including word tokenizing:"
      ],
      "metadata": {
        "id": "mBAHrVXtd0HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "vf5nZUysdqnm"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text\n",
        "string = \"The science of today is the technology of tomorrow\""
      ],
      "metadata": {
        "id": "JZYCG6yfjiGg"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the library\n",
        "import nltk"
      ],
      "metadata": {
        "id": "Ie_awMSNkGuk"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowload 'punkt\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2inFPkjkQXE",
        "outputId": "ec22ebe3-7f96-4a64-aa14-1df6e9247db8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the string\n",
        "word_tokenize(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c409pIqSkiVq",
        "outputId": "beb907ff-a99b-4ff7-975b-c96ee3d782fd"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(\"Bonjour tout le monde, je suis chez moi à la maison. Content de vous parler\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41QBZpp6lK3N",
        "outputId": "40992ff5-1892-40f6-b0a6-37f6b56c863d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bonjour',\n",
              " 'tout',\n",
              " 'le',\n",
              " 'monde',\n",
              " ',',\n",
              " 'je',\n",
              " 'suis',\n",
              " 'chez',\n",
              " 'moi',\n",
              " 'à',\n",
              " 'la',\n",
              " 'maison',\n",
              " '.',\n",
              " 'Content',\n",
              " 'de',\n",
              " 'vous',\n",
              " 'parler']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also tokenize in sentence"
      ],
      "metadata": {
        "id": "Wcr6cPKnm2t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "NI3IXtozmn0a"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize in the sentence\n",
        "sent_tokenize(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s0AzIKpm-Pi",
        "outputId": "ce3f5096-ce9f-4bd0-b7a8-c3baaa8e0683"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The science of today is the technology of tomorrow']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xolpgx4znDbv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}